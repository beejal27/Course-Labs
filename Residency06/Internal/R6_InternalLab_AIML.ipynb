{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sb7Epo0VOB58"
   },
   "source": [
    "### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fHpCNRv1OB5-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import zscore\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Nadam, SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnSsH8sNOB6F",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Reset Default graph - Needed only for Jupyter notebook\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DxJDmJqqOB6K",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FhllFLyKOB6N"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B4yQKMiJOB6R"
   },
   "outputs": [],
   "source": [
    "df_prices = pd.read_csv('./prices.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fgkX6SEqOB6W"
   },
   "source": [
    "### Check all columns in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7K8pWsNQOB6X"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-05 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>123.430000</td>\n",
       "      <td>125.839996</td>\n",
       "      <td>122.309998</td>\n",
       "      <td>126.250000</td>\n",
       "      <td>2163600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-06 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>125.239998</td>\n",
       "      <td>119.980003</td>\n",
       "      <td>119.940002</td>\n",
       "      <td>125.540001</td>\n",
       "      <td>2386400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-07 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>116.379997</td>\n",
       "      <td>114.949997</td>\n",
       "      <td>114.930000</td>\n",
       "      <td>119.739998</td>\n",
       "      <td>2489500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-08 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>115.480003</td>\n",
       "      <td>116.620003</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>117.440002</td>\n",
       "      <td>2006300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-11 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>117.010002</td>\n",
       "      <td>114.970001</td>\n",
       "      <td>114.089996</td>\n",
       "      <td>117.330002</td>\n",
       "      <td>1408600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date symbol        open       close         low        high  \\\n",
       "0  2016-01-05 00:00:00   WLTW  123.430000  125.839996  122.309998  126.250000   \n",
       "1  2016-01-06 00:00:00   WLTW  125.239998  119.980003  119.940002  125.540001   \n",
       "2  2016-01-07 00:00:00   WLTW  116.379997  114.949997  114.930000  119.739998   \n",
       "3  2016-01-08 00:00:00   WLTW  115.480003  116.620003  113.500000  117.440002   \n",
       "4  2016-01-11 00:00:00   WLTW  117.010002  114.970001  114.089996  117.330002   \n",
       "\n",
       "      volume  \n",
       "0  2163600.0  \n",
       "1  2386400.0  \n",
       "2  2489500.0  \n",
       "3  2006300.0  \n",
       "4  1408600.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>851264</td>\n",
       "      <td>851264</td>\n",
       "      <td>851264.000000</td>\n",
       "      <td>851264.000000</td>\n",
       "      <td>851264.000000</td>\n",
       "      <td>851264.000000</td>\n",
       "      <td>8.512640e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3524</td>\n",
       "      <td>501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2016-07-28</td>\n",
       "      <td>MRO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>498</td>\n",
       "      <td>1762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.836986</td>\n",
       "      <td>70.857109</td>\n",
       "      <td>70.118414</td>\n",
       "      <td>71.543476</td>\n",
       "      <td>5.415113e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.695876</td>\n",
       "      <td>83.689686</td>\n",
       "      <td>82.877294</td>\n",
       "      <td>84.465504</td>\n",
       "      <td>1.249468e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.840000</td>\n",
       "      <td>33.849998</td>\n",
       "      <td>33.480000</td>\n",
       "      <td>34.189999</td>\n",
       "      <td>1.221500e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.770000</td>\n",
       "      <td>52.799999</td>\n",
       "      <td>52.230000</td>\n",
       "      <td>53.310001</td>\n",
       "      <td>2.476250e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.879997</td>\n",
       "      <td>79.889999</td>\n",
       "      <td>79.110001</td>\n",
       "      <td>80.610001</td>\n",
       "      <td>5.222500e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1584.439941</td>\n",
       "      <td>1578.130005</td>\n",
       "      <td>1549.939941</td>\n",
       "      <td>1600.930054</td>\n",
       "      <td>8.596434e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  symbol           open          close            low  \\\n",
       "count       851264  851264  851264.000000  851264.000000  851264.000000   \n",
       "unique        3524     501            NaN            NaN            NaN   \n",
       "top     2016-07-28     MRO            NaN            NaN            NaN   \n",
       "freq           498    1762            NaN            NaN            NaN   \n",
       "mean           NaN     NaN      70.836986      70.857109      70.118414   \n",
       "std            NaN     NaN      83.695876      83.689686      82.877294   \n",
       "min            NaN     NaN       0.850000       0.860000       0.830000   \n",
       "25%            NaN     NaN      33.840000      33.849998      33.480000   \n",
       "50%            NaN     NaN      52.770000      52.799999      52.230000   \n",
       "75%            NaN     NaN      79.879997      79.889999      79.110001   \n",
       "max            NaN     NaN    1584.439941    1578.130005    1549.939941   \n",
       "\n",
       "                 high        volume  \n",
       "count   851264.000000  8.512640e+05  \n",
       "unique            NaN           NaN  \n",
       "top               NaN           NaN  \n",
       "freq              NaN           NaN  \n",
       "mean        71.543476  5.415113e+06  \n",
       "std         84.465504  1.249468e+07  \n",
       "min          0.880000  0.000000e+00  \n",
       "25%         34.189999  1.221500e+06  \n",
       "50%         53.310001  2.476250e+06  \n",
       "75%         80.610001  5.222500e+06  \n",
       "max       1600.930054  8.596434e+08  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prices.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7dU6X7MpOB6c"
   },
   "source": [
    "### Drop columns `date` and  `symbol`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lh_6spSKOB6e"
   },
   "outputs": [],
   "source": [
    "df_prices.drop(['date', 'symbol'], axis=1, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xlwbUgTwOB6i",
    "outputId": "56bad82a-f271-415a-e0d6-cbe1c4290743"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123.430000</td>\n",
       "      <td>125.839996</td>\n",
       "      <td>122.309998</td>\n",
       "      <td>126.250000</td>\n",
       "      <td>2163600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125.239998</td>\n",
       "      <td>119.980003</td>\n",
       "      <td>119.940002</td>\n",
       "      <td>125.540001</td>\n",
       "      <td>2386400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.379997</td>\n",
       "      <td>114.949997</td>\n",
       "      <td>114.930000</td>\n",
       "      <td>119.739998</td>\n",
       "      <td>2489500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115.480003</td>\n",
       "      <td>116.620003</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>117.440002</td>\n",
       "      <td>2006300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117.010002</td>\n",
       "      <td>114.970001</td>\n",
       "      <td>114.089996</td>\n",
       "      <td>117.330002</td>\n",
       "      <td>1408600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         open       close         low        high     volume\n",
       "0  123.430000  125.839996  122.309998  126.250000  2163600.0\n",
       "1  125.239998  119.980003  119.940002  125.540001  2386400.0\n",
       "2  116.379997  114.949997  114.930000  119.739998  2489500.0\n",
       "3  115.480003  116.620003  113.500000  117.440002  2006300.0\n",
       "4  117.010002  114.970001  114.089996  117.330002  1408600.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3DBv3WWYOB6q"
   },
   "source": [
    "### Consider only first 1000 rows in the dataset for building feature set and target set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z_hG9rGBOB6s"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prices_mini = df_prices[0:1000]\n",
    "df_prices_mini.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M3UaApqYOB6x"
   },
   "source": [
    "### Divide the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2EkKAy7fOB6y"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 4), 1000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_prices_mini.drop('close', axis=1)\n",
    "X = X.apply(zscore)\n",
    "y = df_prices_mini['close']\n",
    "y = zscore(y)\n",
    "y = [[v] for v in y]\n",
    "\n",
    "X.shape, len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((700, 4), (300, 4), 700, 300)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples, n_features = X_train.shape[0], X_train.shape[1]\n",
    "n_samples, n_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v6vE4eYCOB62",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building the graph in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Beejal\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "X_placeholder = tf.placeholder(tf.float32, shape=[None, n_features])\n",
    "y_placeholder = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "W = tf.Variable(tf.random_normal(shape=[n_features, 1]))\n",
    "b = tf.Variable(rs.rand())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_placeholder =  Tensor(\"Placeholder:0\", shape=(?, 4), dtype=float32)\n",
      "y_placeholder =  Tensor(\"Placeholder_1:0\", shape=(?, 1), dtype=float32)\n",
      "W =  <tf.Variable 'Variable:0' shape=(4, 1) dtype=float32_ref>\n",
      "b =  <tf.Variable 'Variable_1:0' shape=() dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "print(\"X_placeholder = \" , X_placeholder)\n",
    "print(\"y_placeholder = \", y_placeholder)\n",
    "print(\"W = \", W)\n",
    "print(\"b = \", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xK0zBd1VOB64",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1.Define input data placeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "297_qja4OB7A",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2.Define Weights and Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HgtWA-UIOB7F",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3.Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JveGlx25OB7H"
   },
   "outputs": [],
   "source": [
    "y_hat = tf.add(tf.matmul(X_placeholder, W),  b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TL1hIwf_OB7M",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "4.Loss (Cost) Function [Mean square error]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8VSWPiGXOB7P"
   },
   "outputs": [],
   "source": [
    "# Mean squared error \n",
    "cost = tf.reduce_mean(tf.square(tf.subtract(y_placeholder, y_hat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jzG85FUlOB7U",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "5.GradientDescent Optimizer to minimize Loss [GradientDescentOptimizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cj802w-3OB7X"
   },
   "outputs": [],
   "source": [
    "# Gradient descent \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost) # opearational tensor\n",
    "\n",
    "# Initializing the variables \n",
    "init = tf.global_variables_initializer() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xSypb_u8OB7e",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Execute the Graph for 100 epochs and observe the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs = 100\n",
    "display_step = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DVvgj7eQOB7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:20 \t Cost:0.05083097890019417 \t W:['[-0.9132568]', '[1.0919683]', '[0.7620585]', '[-0.20498997]'] \t b:0.08194610476493835\n",
      "Epoch:40 \t Cost:0.0007842706982046366 \t W:['[-0.8958571]', '[1.1092755]', '[0.779468]', '[-0.02407327]'] \t b:0.009406397119164467\n",
      "Epoch:60 \t Cost:9.757715451996773e-05 \t W:['[-0.89366984]', '[1.1113361]', '[0.7816444]', '[-0.00284594]'] \t b:0.0010751377558335662\n",
      "Epoch:80 \t Cost:8.814118336886168e-05 \t W:['[-0.8933699]', '[1.1115057]', '[0.7819311]', '[-0.00035117]'] \t b:0.00011997971159871668\n",
      "Epoch:100 \t Cost:8.800152863841504e-05 \t W:['[-0.89329195]', '[1.1114526]', '[0.7819951]', '[-5.790812e-05]'] \t b:1.0635621947585605e-05\n",
      "Optimization Finished!\n",
      "Final training cost: 8.800153e-05 W: [[-8.9329195e-01]\n",
      " [ 1.1114526e+00]\n",
      " [ 7.8199512e-01]\n",
      " [-5.7908121e-05]] b: 1.0635622e-05 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final testing cost: 0.00011511242\n",
      "Absolute mean square loss difference: 2.7110895e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess: \n",
    "    # Load initialized variables in current session \n",
    "    sess.run(init) \n",
    "\n",
    "    # Fit all training data \n",
    "    for epoch in range(training_epochs): \n",
    "\n",
    "        # perform gradient descent step \n",
    "        sess.run(optimizer, feed_dict={X_placeholder: X_train, y_placeholder: y_train}) \n",
    "        \n",
    "        # Display logs per epoch step \n",
    "        if (epoch + 1) % display_step == 0: \n",
    "            c = sess.run(cost, feed_dict={X_placeholder: X_train, y_placeholder: y_train}) \n",
    "            print(\"Epoch:{} \\t Cost:{} \\t W:{} \\t b:{}\".format(epoch+1, c, [str(w) for w in sess.run(W)], sess.run(b))) \n",
    "\n",
    "    # Print final parameter values \n",
    "    print(\"Optimization Finished!\") \n",
    "    training_cost = sess.run(cost, feed_dict={X_placeholder: X_train, y_placeholder: y_train}) \n",
    "    print(\"Final training cost:\", training_cost, \"W:\", sess.run(W), \"b:\", sess.run(b), '\\n') \n",
    "       \n",
    "    # Graphic display \n",
    "    y_train_pred = sess.run(y_hat, feed_dict={X_placeholder: X_train})\n",
    "    plt.plot(X_train['open'], y_train, 'ro', label='Original data') \n",
    "    plt.plot(X_train['open'], y_train_pred, label='Fitted line') \n",
    "    plt.xlabel(\"Opening Price\")\n",
    "    plt.ylabel(\"Closing Price\")\n",
    "    plt.legend() \n",
    "    plt.show() \n",
    "\n",
    "    # Testing the model \n",
    "    testing_cost = sess.run(cost, feed_dict={X_placeholder: X_test, y_placeholder: y_test}) \n",
    "    \n",
    "    print(\"Final testing cost:\", testing_cost) \n",
    "    print(\"Absolute mean square loss difference:\", abs(training_cost - testing_cost)) \n",
    "\n",
    "    # Display fitted line on test data \n",
    "    y_test_pred = sess.run(y_hat, feed_dict={X_placeholder: X_test})\n",
    "    plt.plot(X_test['open'], y_test, 'bo', label='Testing data') \n",
    "    plt.plot(X_train['open'], y_train_pred, label='Fitted line') \n",
    "    plt.xlabel(\"Opening Price\")\n",
    "    plt.ylabel(\"Closing Price\")\n",
    "    plt.legend() \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DOL2ncA1OB7q"
   },
   "source": [
    "### Get the shapes and values of W and b\n",
    "\n",
    "Hint: Use sess.run(W) to get W."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZGvtyTeuOB7r"
   },
   "outputs": [],
   "source": [
    "# Beejal - Done above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SZqKUEFsOB71"
   },
   "source": [
    "### Find the Absolute mean square loss difference between training and testing loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97t-grQgOB71"
   },
   "outputs": [],
   "source": [
    "# Beejal - Done above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YJRBuqXhOB7_"
   },
   "source": [
    "### Linear Classification using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GoNTWXAOB8C",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Building the simple Neural Network in Keras with one neuron in the dense hidden layer.\n",
    "#### Use Mean square error as loss function and sgd as optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zpeL5rCTOB8D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 7\n",
      "Trainable params: 7\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() # the first layer has to specify the dimensions of the input vector \n",
    "model.add( Dense( units = 1, activation ='sigmoid', input_shape =( n_features,)))\n",
    "model.add( Dense( units = 1, activation ='linear')) # print the summary of our model \n",
    "model.summary() \n",
    "\n",
    "# compile the model \n",
    "model.compile( loss ='mse', optimizer = SGD(), metrics =['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wt-HYFMEOB8G",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=50\n",
    "n_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_prices_mini.drop('close', axis=1)\n",
    "y = df_prices_mini['close']\n",
    "X = X.apply(zscore)\n",
    "y = zscore(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "66JGJt7GOB8H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Beejal\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "700/700 [==============================] - 0s 331us/step - loss: 0.8969 - mean_absolute_error: 0.7120\n",
      "Epoch 2/20\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.8919 - mean_absolute_error: 0.7055\n",
      "Epoch 3/20\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.8886 - mean_absolute_error: 0.7018\n",
      "Epoch 4/20\n",
      "700/700 [==============================] - 0s 36us/step - loss: 0.8851 - mean_absolute_error: 0.6973\n",
      "Epoch 5/20\n",
      "700/700 [==============================] - 0s 34us/step - loss: 0.8821 - mean_absolute_error: 0.6933\n",
      "Epoch 6/20\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.8783 - mean_absolute_error: 0.6914\n",
      "Epoch 7/20\n",
      "700/700 [==============================] - 0s 31us/step - loss: 0.8749 - mean_absolute_error: 0.6892\n",
      "Epoch 8/20\n",
      "700/700 [==============================] - 0s 41us/step - loss: 0.8708 - mean_absolute_error: 0.6858\n",
      "Epoch 9/20\n",
      "700/700 [==============================] - 0s 34us/step - loss: 0.8664 - mean_absolute_error: 0.6839\n",
      "Epoch 10/20\n",
      "700/700 [==============================] - 0s 42us/step - loss: 0.8614 - mean_absolute_error: 0.6821\n",
      "Epoch 11/20\n",
      "700/700 [==============================] - 0s 39us/step - loss: 0.8561 - mean_absolute_error: 0.6816\n",
      "Epoch 12/20\n",
      "700/700 [==============================] - 0s 42us/step - loss: 0.8504 - mean_absolute_error: 0.6760\n",
      "Epoch 13/20\n",
      "700/700 [==============================] - 0s 41us/step - loss: 0.8442 - mean_absolute_error: 0.6743\n",
      "Epoch 14/20\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.8373 - mean_absolute_error: 0.6710\n",
      "Epoch 15/20\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.8296 - mean_absolute_error: 0.6673\n",
      "Epoch 16/20\n",
      "700/700 [==============================] - 0s 42us/step - loss: 0.8221 - mean_absolute_error: 0.6643\n",
      "Epoch 17/20\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.8138 - mean_absolute_error: 0.6585\n",
      "Epoch 18/20\n",
      "700/700 [==============================] - 0s 47us/step - loss: 0.8044 - mean_absolute_error: 0.6534\n",
      "Epoch 19/20\n",
      "700/700 [==============================] - 0s 43us/step - loss: 0.7947 - mean_absolute_error: 0.6499\n",
      "Epoch 20/20\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.7843 - mean_absolute_error: 0.6430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2254e3b1080>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit( X_train, y_train, batch_size = batch_size, epochs = n_epochs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 224us/step\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.1009619104862214\n",
      "mae: 0.6653611946105957\n"
     ]
    }
   ],
   "source": [
    "print('loss:', scores[0]) \n",
    "print('mae:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UbUPQ2iGTyOC"
   },
   "source": [
    "### Classification using Keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YxJfb_2vTyOD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hRouHBtITyOF"
   },
   "source": [
    "### Load the given Iris data using pandas (Iris.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yEN7BRzvTyOF"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8wbhz0SgTyOI"
   },
   "source": [
    "### Splitting the data into feature set and target set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "If4kadhPTyOJ"
   },
   "outputs": [],
   "source": [
    "df.drop('Id', axis=1, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Species', axis=1)\n",
    "y = df['Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), 150)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QuLlR5E8TyOP"
   },
   "source": [
    "### Target set has different categories. So, Label encode them. And convert into one-hot vectors using get_dummies in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lui4BZRgTyOR"
   },
   "outputs": [],
   "source": [
    "y_en = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Iris-setosa  Iris-versicolor  Iris-virginica\n",
       "0            1                0               0\n",
       "1            1                0               0\n",
       "2            1                0               0\n",
       "3            1                0               0\n",
       "4            1                0               0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_en.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QBCfIFH8TyOV"
   },
   "source": [
    "### Divide the dataset into Training and test (70:30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_en, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 4), (50, 4), (100, 3), (50, 3))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N31GZ7-YTyOY"
   },
   "source": [
    "### Model\n",
    "Build the model with following layers: <br>\n",
    "1. First dense layer with 10 neurons with input shape 4 (according to the feature set) <br>\n",
    "2. Second Dense layer with 8 neurons <br>\n",
    "3. Output layer with 3 neurons with softmax activation (output layer, 3 neurons as we have 3 classes) <br>\n",
    "4. Use SGD and categorical_crossentropy loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5mNXvtQiTyOa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Beejal\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 165\n",
      "Trainable params: 165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define some hyper parameters \n",
    "n_inputs = 4\n",
    "n_classes = len(y.unique())\n",
    "batch_size = 100 \n",
    "n_epochs = 150\n",
    "\n",
    "# [Beejal] To achieve more accuracy, I have used 'relu' as activation function (Non Linear function) \n",
    "# & Optimizer as 'Nadam'.\n",
    "# Combination of 'sigmoid' as activation function (Non Linear function) & SGD (Linear function)\n",
    "# was giving just 30% accuracy\n",
    "model = Sequential() # the first layer has to specify the dimensions of the input vector \n",
    "model.add( Dense( units = 10, activation ='relu', input_shape =( n_inputs,))) # add dropout layer for preventing overfitting \n",
    "model.add( Dropout( 0.1)) \n",
    "model.add( Dense( units = 8, activation ='relu')) \n",
    "model.add( Dropout( 0.1)) # output layer can only have the neurons equal to the number of outputs \n",
    "model.add( Dense( units = n_classes, activation ='softmax')) # print the summary of our model \n",
    "model.summary() \n",
    "\n",
    "# compile the model \n",
    "model.compile( loss ='categorical_crossentropy', optimizer = Nadam(), metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IMqTdhwfTyOf"
   },
   "source": [
    "### Fitting the model and predicting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z9tI_ZAJTyOg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 5.3817 - acc: 0.3500\n",
      "Epoch 2/150\n",
      "100/100 [==============================] - 0s 61us/step - loss: 5.3198 - acc: 0.3500\n",
      "Epoch 3/150\n",
      "100/100 [==============================] - 0s 10us/step - loss: 4.8868 - acc: 0.3500\n",
      "Epoch 4/150\n",
      "100/100 [==============================] - 0s 32us/step - loss: 5.0827 - acc: 0.3500\n",
      "Epoch 5/150\n",
      "100/100 [==============================] - 0s 52us/step - loss: 4.6884 - acc: 0.3500\n",
      "Epoch 6/150\n",
      "100/100 [==============================] - 0s 37us/step - loss: 4.5133 - acc: 0.3500\n",
      "Epoch 7/150\n",
      "100/100 [==============================] - 0s 34us/step - loss: 4.2811 - acc: 0.3500\n",
      "Epoch 8/150\n",
      "100/100 [==============================] - 0s 36us/step - loss: 4.6672 - acc: 0.3500\n",
      "Epoch 9/150\n",
      "100/100 [==============================] - 0s 46us/step - loss: 4.4417 - acc: 0.3500\n",
      "Epoch 10/150\n",
      "100/100 [==============================] - 0s 28us/step - loss: 4.1679 - acc: 0.3500\n",
      "Epoch 11/150\n",
      "100/100 [==============================] - 0s 40us/step - loss: 4.1584 - acc: 0.3500\n",
      "Epoch 12/150\n",
      "100/100 [==============================] - 0s 57us/step - loss: 3.9685 - acc: 0.3500\n",
      "Epoch 13/150\n",
      "100/100 [==============================] - 0s 37us/step - loss: 3.4950 - acc: 0.3500\n",
      "Epoch 14/150\n",
      "100/100 [==============================] - 0s 44us/step - loss: 3.7240 - acc: 0.3500\n",
      "Epoch 15/150\n",
      "100/100 [==============================] - 0s 23us/step - loss: 3.4174 - acc: 0.3500\n",
      "Epoch 16/150\n",
      "100/100 [==============================] - 0s 30us/step - loss: 3.2927 - acc: 0.3500\n",
      "Epoch 17/150\n",
      "100/100 [==============================] - 0s 34us/step - loss: 3.2237 - acc: 0.3500\n",
      "Epoch 18/150\n",
      "100/100 [==============================] - 0s 36us/step - loss: 3.1130 - acc: 0.3500\n",
      "Epoch 19/150\n",
      "100/100 [==============================] - 0s 32us/step - loss: 3.0772 - acc: 0.3500\n",
      "Epoch 20/150\n",
      "100/100 [==============================] - 0s 41us/step - loss: 2.5991 - acc: 0.3500\n",
      "Epoch 21/150\n",
      "100/100 [==============================] - 0s 47us/step - loss: 2.6987 - acc: 0.3500\n",
      "Epoch 22/150\n",
      "100/100 [==============================] - 0s 84us/step - loss: 2.5769 - acc: 0.3500\n",
      "Epoch 23/150\n",
      "100/100 [==============================] - 0s 45us/step - loss: 2.5773 - acc: 0.3400\n",
      "Epoch 24/150\n",
      "100/100 [==============================] - 0s 41us/step - loss: 2.3844 - acc: 0.3500\n",
      "Epoch 25/150\n",
      "100/100 [==============================] - 0s 49us/step - loss: 2.3116 - acc: 0.3700\n",
      "Epoch 26/150\n",
      "100/100 [==============================] - 0s 21us/step - loss: 2.0323 - acc: 0.3600\n",
      "Epoch 27/150\n",
      "100/100 [==============================] - 0s 40us/step - loss: 2.3141 - acc: 0.3600\n",
      "Epoch 28/150\n",
      "100/100 [==============================] - 0s 82us/step - loss: 2.0822 - acc: 0.3400\n",
      "Epoch 29/150\n",
      "100/100 [==============================] - 0s 40us/step - loss: 1.9868 - acc: 0.3400\n",
      "Epoch 30/150\n",
      "100/100 [==============================] - 0s 41us/step - loss: 1.9824 - acc: 0.3600\n",
      "Epoch 31/150\n",
      "100/100 [==============================] - 0s 53us/step - loss: 1.9018 - acc: 0.3300\n",
      "Epoch 32/150\n",
      "100/100 [==============================] - 0s 44us/step - loss: 1.8961 - acc: 0.3600\n",
      "Epoch 33/150\n",
      "100/100 [==============================] - 0s 52us/step - loss: 1.6160 - acc: 0.3400\n",
      "Epoch 34/150\n",
      "100/100 [==============================] - 0s 37us/step - loss: 1.5785 - acc: 0.3900\n",
      "Epoch 35/150\n",
      "100/100 [==============================] - 0s 43us/step - loss: 1.4719 - acc: 0.4000\n",
      "Epoch 36/150\n",
      "100/100 [==============================] - 0s 10us/step - loss: 1.5848 - acc: 0.3600\n",
      "Epoch 37/150\n",
      "100/100 [==============================] - 0s 10us/step - loss: 1.5039 - acc: 0.4200\n",
      "Epoch 38/150\n",
      "100/100 [==============================] - 0s 0us/step - loss: 1.5030 - acc: 0.3900\n",
      "Epoch 39/150\n",
      "100/100 [==============================] - 0s 37us/step - loss: 1.6023 - acc: 0.3100\n",
      "Epoch 40/150\n",
      "100/100 [==============================] - 0s 60us/step - loss: 1.3771 - acc: 0.3500\n",
      "Epoch 41/150\n",
      "100/100 [==============================] - 0s 57us/step - loss: 1.2823 - acc: 0.4200\n",
      "Epoch 42/150\n",
      "100/100 [==============================] - 0s 42us/step - loss: 1.3886 - acc: 0.3900\n",
      "Epoch 43/150\n",
      "100/100 [==============================] - 0s 44us/step - loss: 1.2065 - acc: 0.4000\n",
      "Epoch 44/150\n",
      "100/100 [==============================] - 0s 43us/step - loss: 1.3196 - acc: 0.2800\n",
      "Epoch 45/150\n",
      "100/100 [==============================] - 0s 50us/step - loss: 1.1884 - acc: 0.4400\n",
      "Epoch 46/150\n",
      "100/100 [==============================] - 0s 54us/step - loss: 1.0949 - acc: 0.4300\n",
      "Epoch 47/150\n",
      "100/100 [==============================] - 0s 21us/step - loss: 1.2459 - acc: 0.4000\n",
      "Epoch 48/150\n",
      "100/100 [==============================] - 0s 10us/step - loss: 1.0936 - acc: 0.4400\n",
      "Epoch 49/150\n",
      "100/100 [==============================] - 0s 48us/step - loss: 1.1133 - acc: 0.4300\n",
      "Epoch 50/150\n",
      "100/100 [==============================] - 0s 35us/step - loss: 1.2723 - acc: 0.4000\n",
      "Epoch 51/150\n",
      "100/100 [==============================] - 0s 26us/step - loss: 1.1088 - acc: 0.4600\n",
      "Epoch 52/150\n",
      "100/100 [==============================] - 0s 43us/step - loss: 1.0829 - acc: 0.4400\n",
      "Epoch 53/150\n",
      "100/100 [==============================] - 0s 30us/step - loss: 1.0018 - acc: 0.4700\n",
      "Epoch 54/150\n",
      "100/100 [==============================] - 0s 0us/step - loss: 1.0938 - acc: 0.4500\n",
      "Epoch 55/150\n",
      "100/100 [==============================] - 0s 40us/step - loss: 0.9979 - acc: 0.4500\n",
      "Epoch 56/150\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.9863 - acc: 0.4600\n",
      "Epoch 57/150\n",
      "100/100 [==============================] - 0s 38us/step - loss: 0.9971 - acc: 0.5100\n",
      "Epoch 58/150\n",
      "100/100 [==============================] - 0s 37us/step - loss: 0.9777 - acc: 0.4600\n",
      "Epoch 59/150\n",
      "100/100 [==============================] - 0s 19us/step - loss: 1.0306 - acc: 0.4100\n",
      "Epoch 60/150\n",
      "100/100 [==============================] - 0s 34us/step - loss: 1.0218 - acc: 0.5000\n",
      "Epoch 61/150\n",
      "100/100 [==============================] - 0s 34us/step - loss: 1.0532 - acc: 0.5000\n",
      "Epoch 62/150\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.9805 - acc: 0.5300\n",
      "Epoch 63/150\n",
      "100/100 [==============================] - 0s 21us/step - loss: 0.9632 - acc: 0.5000\n",
      "Epoch 64/150\n",
      "100/100 [==============================] - 0s 39us/step - loss: 0.9861 - acc: 0.5800\n",
      "Epoch 65/150\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.9250 - acc: 0.5600\n",
      "Epoch 66/150\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.9463 - acc: 0.5500\n",
      "Epoch 67/150\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.9134 - acc: 0.6300\n",
      "Epoch 68/150\n",
      "100/100 [==============================] - 0s 34us/step - loss: 0.9991 - acc: 0.5300\n",
      "Epoch 69/150\n",
      "100/100 [==============================] - 0s 0us/step - loss: 1.0159 - acc: 0.5200\n",
      "Epoch 70/150\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.9953 - acc: 0.6000\n",
      "Epoch 71/150\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.9484 - acc: 0.5700\n",
      "Epoch 72/150\n",
      "100/100 [==============================] - 0s 22us/step - loss: 0.9055 - acc: 0.6000\n",
      "Epoch 73/150\n",
      "100/100 [==============================] - 0s 35us/step - loss: 0.9215 - acc: 0.6200\n",
      "Epoch 74/150\n",
      "100/100 [==============================] - 0s 40us/step - loss: 0.8866 - acc: 0.5900\n",
      "Epoch 75/150\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.8558 - acc: 0.6600\n",
      "Epoch 76/150\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.8344 - acc: 0.6500\n",
      "Epoch 77/150\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.8976 - acc: 0.5800\n",
      "Epoch 78/150\n",
      "100/100 [==============================] - 0s 21us/step - loss: 0.8689 - acc: 0.6000\n",
      "Epoch 79/150\n",
      "100/100 [==============================] - 0s 28us/step - loss: 0.9037 - acc: 0.6200\n",
      "Epoch 80/150\n",
      "100/100 [==============================] - 0s 43us/step - loss: 0.8551 - acc: 0.6900\n",
      "Epoch 81/150\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.8978 - acc: 0.6200\n",
      "Epoch 82/150\n",
      "100/100 [==============================] - 0s 41us/step - loss: 0.9306 - acc: 0.6000\n",
      "Epoch 83/150\n",
      "100/100 [==============================] - 0s 37us/step - loss: 0.8293 - acc: 0.6500\n",
      "Epoch 84/150\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.8615 - acc: 0.6400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/150\n",
      "100/100 [==============================] - 0s 48us/step - loss: 0.9050 - acc: 0.6900\n",
      "Epoch 86/150\n",
      "100/100 [==============================] - 0s 27us/step - loss: 0.9223 - acc: 0.6300\n",
      "Epoch 87/150\n",
      "100/100 [==============================] - 0s 45us/step - loss: 0.8532 - acc: 0.6600\n",
      "Epoch 88/150\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.8580 - acc: 0.6400\n",
      "Epoch 89/150\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.9450 - acc: 0.6200\n",
      "Epoch 90/150\n",
      "100/100 [==============================] - 0s 41us/step - loss: 0.8782 - acc: 0.6500\n",
      "Epoch 91/150\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.8663 - acc: 0.6100\n",
      "Epoch 92/150\n",
      "100/100 [==============================] - 0s 48us/step - loss: 0.8165 - acc: 0.7000\n",
      "Epoch 93/150\n",
      "100/100 [==============================] - 0s 64us/step - loss: 0.8262 - acc: 0.6600\n",
      "Epoch 94/150\n",
      "100/100 [==============================] - 0s 23us/step - loss: 0.7474 - acc: 0.7000\n",
      "Epoch 95/150\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.8582 - acc: 0.6500\n",
      "Epoch 96/150\n",
      "100/100 [==============================] - 0s 64us/step - loss: 0.8770 - acc: 0.6300\n",
      "Epoch 97/150\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.8537 - acc: 0.6300\n",
      "Epoch 98/150\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.8919 - acc: 0.5900\n",
      "Epoch 99/150\n",
      "100/100 [==============================] - 0s 41us/step - loss: 0.8367 - acc: 0.6600\n",
      "Epoch 100/150\n",
      "100/100 [==============================] - 0s 41us/step - loss: 0.8641 - acc: 0.6400\n",
      "Epoch 101/150\n",
      "100/100 [==============================] - 0s 42us/step - loss: 0.8566 - acc: 0.6300\n",
      "Epoch 102/150\n",
      "100/100 [==============================] - 0s 66us/step - loss: 0.8380 - acc: 0.6400\n",
      "Epoch 103/150\n",
      "100/100 [==============================] - 0s 0us/step - loss: 0.7107 - acc: 0.7100\n",
      "Epoch 104/150\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.8417 - acc: 0.6500\n",
      "Epoch 105/150\n",
      "100/100 [==============================] - 0s 40us/step - loss: 0.7824 - acc: 0.7000\n",
      "Epoch 106/150\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.7665 - acc: 0.7100\n",
      "Epoch 107/150\n",
      "100/100 [==============================] - 0s 35us/step - loss: 0.8125 - acc: 0.6900\n",
      "Epoch 108/150\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.7928 - acc: 0.6400\n",
      "Epoch 109/150\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.8770 - acc: 0.5800\n",
      "Epoch 110/150\n",
      "100/100 [==============================] - 0s 13us/step - loss: 0.6818 - acc: 0.7200\n",
      "Epoch 111/150\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.8481 - acc: 0.6700\n",
      "Epoch 112/150\n",
      "100/100 [==============================] - 0s 10us/step - loss: 0.7667 - acc: 0.7000\n",
      "Epoch 113/150\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.8389 - acc: 0.5800\n",
      "Epoch 114/150\n",
      "100/100 [==============================] - 0s 30us/step - loss: 0.7054 - acc: 0.6800\n",
      "Epoch 115/150\n",
      "100/100 [==============================] - 0s 37us/step - loss: 0.7969 - acc: 0.6300\n",
      "Epoch 116/150\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.7992 - acc: 0.6800\n",
      "Epoch 117/150\n",
      "100/100 [==============================] - 0s 29us/step - loss: 0.7650 - acc: 0.6900\n",
      "Epoch 118/150\n",
      "100/100 [==============================] - 0s 47us/step - loss: 0.8501 - acc: 0.6300\n",
      "Epoch 119/150\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.8636 - acc: 0.6400\n",
      "Epoch 120/150\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.7528 - acc: 0.6900\n",
      "Epoch 121/150\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.7647 - acc: 0.6100\n",
      "Epoch 122/150\n",
      "100/100 [==============================] - 0s 42us/step - loss: 0.7943 - acc: 0.6500\n",
      "Epoch 123/150\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.8002 - acc: 0.6000\n",
      "Epoch 124/150\n",
      "100/100 [==============================] - 0s 49us/step - loss: 0.7257 - acc: 0.7000\n",
      "Epoch 125/150\n",
      "100/100 [==============================] - 0s 49us/step - loss: 0.7877 - acc: 0.6400\n",
      "Epoch 126/150\n",
      "100/100 [==============================] - 0s 42us/step - loss: 0.8080 - acc: 0.6800\n",
      "Epoch 127/150\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.7479 - acc: 0.6200\n",
      "Epoch 128/150\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.7873 - acc: 0.6700\n",
      "Epoch 129/150\n",
      "100/100 [==============================] - 0s 38us/step - loss: 0.8248 - acc: 0.5900\n",
      "Epoch 130/150\n",
      "100/100 [==============================] - 0s 44us/step - loss: 0.7812 - acc: 0.6200\n",
      "Epoch 131/150\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.8287 - acc: 0.6300\n",
      "Epoch 132/150\n",
      "100/100 [==============================] - 0s 44us/step - loss: 0.7786 - acc: 0.6700\n",
      "Epoch 133/150\n",
      "100/100 [==============================] - 0s 41us/step - loss: 0.7825 - acc: 0.6500\n",
      "Epoch 134/150\n",
      "100/100 [==============================] - 0s 38us/step - loss: 0.7224 - acc: 0.7000\n",
      "Epoch 135/150\n",
      "100/100 [==============================] - 0s 48us/step - loss: 0.7504 - acc: 0.7300\n",
      "Epoch 136/150\n",
      "100/100 [==============================] - 0s 33us/step - loss: 0.8288 - acc: 0.6000\n",
      "Epoch 137/150\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.7429 - acc: 0.6700\n",
      "Epoch 138/150\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.7705 - acc: 0.6200\n",
      "Epoch 139/150\n",
      "100/100 [==============================] - 0s 54us/step - loss: 0.7157 - acc: 0.6700\n",
      "Epoch 140/150\n",
      "100/100 [==============================] - 0s 75us/step - loss: 0.8294 - acc: 0.6300\n",
      "Epoch 141/150\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.7046 - acc: 0.7100\n",
      "Epoch 142/150\n",
      "100/100 [==============================] - 0s 40us/step - loss: 0.7918 - acc: 0.5900\n",
      "Epoch 143/150\n",
      "100/100 [==============================] - 0s 20us/step - loss: 0.7925 - acc: 0.6400\n",
      "Epoch 144/150\n",
      "100/100 [==============================] - 0s 58us/step - loss: 0.8037 - acc: 0.6500\n",
      "Epoch 145/150\n",
      "100/100 [==============================] - 0s 31us/step - loss: 0.7668 - acc: 0.6400\n",
      "Epoch 146/150\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.7780 - acc: 0.6200\n",
      "Epoch 147/150\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.6923 - acc: 0.6700\n",
      "Epoch 148/150\n",
      "100/100 [==============================] - 0s 84us/step - loss: 0.6108 - acc: 0.7600\n",
      "Epoch 149/150\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.6606 - acc: 0.7100\n",
      "Epoch 150/150\n",
      "100/100 [==============================] - 0s 71us/step - loss: 0.7055 - acc: 0.6600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2254e8b5400>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model \n",
    "model.fit( X_train, y_train, batch_size = batch_size, epochs = n_epochs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e4-Rfd5iTyOj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model and print the accuracy score \n",
    "scores = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z39NQp9dTyOp"
   },
   "source": [
    "### Report Accuracy of the predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zJL7Lgm-TyOp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5342120730876923\n",
      "accuracy: 0.8599999904632568\n"
     ]
    }
   ],
   "source": [
    "print('loss:', scores[0]) \n",
    "print('accuracy:', scores[1])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "R6_InternalLab_AIML.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
